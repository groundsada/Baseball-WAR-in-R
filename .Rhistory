logit_model <- glm(Top100Status ~ ., data = train_data, family = binomial())
# Predictions
predictions <- predict(logit_model, test_data, type = "response")
predicted_class <- ifelse(predictions <= 0.5, 0, 1)
# Model evaluation
confusionMatrix(factor(predicted_class), factor(test_data$Top100Status))
# Fit logistic regression model
logit_model <- glm(Top100Status ~ ., data = train_data, family = binomial())
# Predictions
predictions <- predict(logit_model, test_data, type = "response")
predicted_class <- ifelse(predictions <= 0.5, 1, 0)
# Model evaluation
confusionMatrix(factor(predicted_class), factor(test_data$Top100Status),positive = "0")
# Fit logistic regression model
logit_model <- glm(Top100Status ~ ., data = train_data, family = binomial())
# Predictions
predictions <- predict(logit_model, test_data, type = "response")
predicted_class <- ifelse(predictions <= 0.5, 1, 0)
# Model evaluation
confusionMatrix(factor(predicted_class), factor(test_data$Top100Status),positive = "0")
# Fit logistic regression model
logit_model <- glm(Top100Status ~ ., data = train_data, family = binomial())
# Predictions
predictions <- predict(logit_model, test_data, type = "response")
predicted_class <- ifelse(predictions <= 0.5, 1, 0)
# Model evaluation
confusionMatrix(factor(predicted_class), factor(test_data$Top100Status),positive = "1")
# Fit logistic regression model
logit_model <- glm(Top100Status ~ ., data = train_data, family = binomial())
# Predictions
predictions <- predict(logit_model, test_data, type = "response")
predicted_class <- ifelse(predictions <= 0.5, 1, 0)
# Model evaluation
confusionMatrix(factor(predicted_class), factor(test_data$Top100Status),positive = "")
# Fit logistic regression model
logit_model <- glm(Top100Status ~ ., data = train_data, family = binomial())
# Predictions
predictions <- predict(logit_model, test_data, type = "response")
predicted_class <- ifelse(predictions <= 0.5, 1, 0)
# Model evaluation
confusionMatrix(factor(predicted_class), factor(test_data$Top100Status), positive = "0")
# Fit logistic regression model
logit_model <- glm(Top100Status ~ ., data = train_data, family = binomial())
# Predictions
predictions <- predict(logit_model, test_data, type = "response")
predicted_class <- ifelse(predictions > 0.5, 1, 0)
# Model evaluation
confusionMatrix(factor(predicted_class), factor(test_data$Top100Status), positive = "0")
# Fit logistic regression model
logit_model <- glm(Top100Status ~ ., data = train_data, family = binomial())
# Predictions
predictions <- predict(logit_model, test_data, type = "response")
predicted_class <- ifelse(predictions > 0.5, 1, 0)
# Model evaluation
confusionMatrix(factor(predicted_class), factor(test_data$Top100Status), positive = "1")
# Fit logistic regression model
logit_model <- glm(Top100Status ~ ., data = train_data, family = binomial())
# Predictions
predictions <- predict(logit_model, test_data, type = "response")
predicted_class <- ifelse(predictions > 0.7, 1, 0)
# Model evaluation
confusionMatrix(factor(predicted_class), factor(test_data$Top100Status), positive = "1")
# Fit logistic regression model
logit_model <- glm(Top100Status ~ ., data = train_data, family = binomial())
# Predictions
predictions <- predict(logit_model, test_data, type = "response")
predicted_class <- ifelse(predictions > 0.2, 1, 0)
# Model evaluation
confusionMatrix(factor(predicted_class), factor(test_data$Top100Status), positive = "1")
# Fit logistic regression model
logit_model <- glm(Top100Status ~ ., data = train_data, family = binomial())
# Predictions
predictions <- predict(logit_model, test_data, type = "response")
predicted_class <- ifelse(predictions > 0.1, 1, 0)
# Model evaluation
confusionMatrix(factor(predicted_class), factor(test_data$Top100Status), positive = "1")
# Fit logistic regression model
logit_model <- glm(Top100Status ~ ., data = train_data, family = binomial())
# Predictions
predictions <- predict(logit_model, test_data, type = "response")
predicted_class <- ifelse(predictions > 0.0.1, 1, 0)
# Fit logistic regression model
logit_model <- glm(Top100Status ~ ., data = train_data, family = binomial())
# Predictions
predictions <- predict(logit_model, test_data, type = "response")
predicted_class <- ifelse(predictions > 0.01, 1, 0)
# Model evaluation
confusionMatrix(factor(predicted_class), factor(test_data$Top100Status), positive = "1")
# Fit logistic regression model
logit_model <- glm(Top100Status ~ ., data = train_data, family = binomial())
# Predictions
predictions <- predict(logit_model, test_data, type = "response")
predicted_class <- ifelse(predictions > 0.034, 1, 0)
# Model evaluation
confusionMatrix(factor(predicted_class), factor(test_data$Top100Status), positive = "1")
# Fit logistic regression model
logit_model <- glm(Top100Status ~ ., data = train_data, family = binomial())
# Predictions
predictions <- predict(logit_model, test_data, type = "response")
predicted_class <- ifelse(predictions > 0.5, 1, 0)
# Model evaluation
confusionMatrix(factor(predicted_class), factor(test_data$Top100Status), positive = "1")
library(glmnet)
# Prepare matrix for glmnet
x <- model.matrix(Top100Status ~ . - 1, data = train_data)  # -1 to exclude intercept
y <- train_data$Top100Status
# Fit model with L1 regularization (Lasso)
lasso_model <- glmnet(x, y, family = "binomial", alpha = 1)
# Fit model with L2 regularization (Ridge)
ridge_model <- glmnet(x, y, family = "binomial", alpha = 0)
# Cross-validation for optimal lambda
cv_lasso <- cv.glmnet(x, y, family = "binomial", type.measure = "class", alpha = 1)
cv_ridge <- cv.glmnet(x, y, family = "binomial", type.measure = "class", alpha = 0)
# Plotting CV results
plot(cv_lasso)
plot(cv_ridge)
library(glmnet)
x <- model.matrix(Top100Status ~ . - 1, data = train_data)  # -1 to exclude intercept
y <- train_data$Top100Status
lasso_model <- glmnet(x, y, family = "binomial", alpha = 1)
ridge_model <- glmnet(x, y, family = "binomial", alpha = 0)
cv_lasso <- cv.glmnet(x, y, family = "binomial", type.measure = "class", alpha = 1)
cv_ridge <- cv.glmnet(x, y, family = "binomial", type.measure = "class", alpha = 0)
plot(cv_lasso)
plot(cv_ridge)
library(caret)
# Predict using the optimal lambda from cross-validation
lasso_pred_prob <- predict(cv_lasso, newx = model.matrix(Top100Status ~ . - 1, data = test_data), s = "lambda.min", type = "response")
ridge_pred_prob <- predict(cv_ridge, newx = model.matrix(Top100Status ~ . - 1, data = test_data), s = "lambda.min", type = "response")
# Convert probabilities to class predictions based on a threshold (default is 0.5)
lasso_pred_class <- ifelse(lasso_pred_prob > 0.5, 1, 0)
ridge_pred_class <- ifelse(ridge_pred_prob > 0.5, 1, 0)
library(caret)
# Predict using the optimal lambda from cross-validation
lasso_pred_prob <- predict(cv_lasso, newx = model.matrix(Top100Status ~ . - 1, data = test_data), s = "lambda.min", type = "response")
ridge_pred_prob <- predict(cv_ridge, newx = model.matrix(Top100Status ~ . - 1, data = test_data), s = "lambda.min", type = "response")
# Convert probabilities to class predictions based on a threshold (default is 0.5)
lasso_pred_class <- ifelse(lasso_pred_prob > 0.5, 1, 0)
ridge_pred_class <- ifelse(ridge_pred_prob > 0.5, 1, 0)
# Confusion matrix for the Lasso model
lasso_conf_matrix <- confusionMatrix(factor(lasso_pred_class), factor(test_data$Top100Status))
print("Confusion Matrix for Lasso Model:")
print(lasso_conf_matrix)
# Confusion matrix for the Ridge model
ridge_conf_matrix <- confusionMatrix(factor(ridge_pred_class), factor(test_data$Top100Status))
print("Confusion Matrix for Ridge Model:")
print(ridge_conf_matrix)
library(rpart)
# Fit decision tree model
tree_model <- rpart(Top100Status ~ ., data = train_data, method = "class")
# Predictions and evaluation
tree_predictions <- predict(tree_model, test_data, type = "class")
confusionMatrix(tree_predictions, factor(test_data$Top100Status))
library(rpart)
# Fit decision tree model
tree_model <- rpart(Top100Status ~ ., data = train_data, method = "class")
# Predictions and evaluation
tree_predictions <- predict(tree_model, test_data, type = "class")
confusionMatrix(tree_predictions, factor(test_data$Top100Status), positive = "1")
library(rpart)
# Fit decision tree model
tree_model <- rpart(Top100Status ~ ., data = train_data, method = "class")
# Predictions and evaluation
tree_predictions <- predict(tree_model, test_data, type = "class")
confusionMatrix(tree_predictions, factor(test_data$Top100Status), positive = "2")
library(rpart)
# Fit decision tree model
tree_model <- rpart(Top100Status ~ ., data = train_data, method = "class")
# Predictions and evaluation
tree_predictions <- predict(tree_model, test_data, type = "class")
confusionMatrix(tree_predictions, factor(test_data$Top100Status), positive = "0")
library(rpart)
# Fit decision tree model
tree_model <- rpart(Top100Status ~ ., data = train_data, method = "class")
# Predictions and evaluation
tree_predictions <- predict(tree_model, test_data, type = "class")
confusionMatrix(tree_predictions, factor(test_data$Top100Status))
library(randomForest)
# Fit random forest model
rf_model <- randomForest(Top100Status ~ ., data = train_data)
yes
# Predictions and evaluation
library(randomForest)
# Fit random forest model
rf_model <- randomForest(Top100Status ~ ., data = train_data)
# Predictions and evaluation
rf_predictions <- predict(rf_model, test_data)
confusionMatrix(rf_predictions, factor(test_data$Top100Status))
library(dplyr)
library(tidyr)
library(caret)
library(corrplot)
data <- read.csv("dataset/processed_data.csv")
data <- data %>% select(-WinsAboveReplacement)
colnames(data)
print(head(data$Top100Status))
data$Top100Status <- ifelse(data$Top100Status == "No", 0, 1)
print(head(data$Top100Status))
set.seed(123)
index <- createDataPartition(data$Top100Status, p = 0.8, list = FALSE)
train_data <- data[index,]
test_data <- data[-index,]
# Fit logistic regression model
logit_model <- glm(Top100Status ~ ., data = train_data, family = binomial())
# Predictions
predictions <- predict(logit_model, test_data, type = "response")
predicted_class <- ifelse(predictions > 0.5, 1, 0)
# Model evaluation
confusionMatrix(factor(predicted_class), factor(test_data$Top100Status), positive = "1")
library(glmnet)
x <- model.matrix(Top100Status ~ . - 1, data = train_data)  # -1 to exclude intercept
y <- train_data$Top100Status
lasso_model <- glmnet(x, y, family = "binomial", alpha = 1)
ridge_model <- glmnet(x, y, family = "binomial", alpha = 0)
cv_lasso <- cv.glmnet(x, y, family = "binomial", type.measure = "class", alpha = 1)
cv_ridge <- cv.glmnet(x, y, family = "binomial", type.measure = "class", alpha = 0)
plot(cv_lasso)
plot(cv_ridge)
library(caret)
# Predict using the optimal lambda from cross-validation
lasso_pred_prob <- predict(cv_lasso, newx = model.matrix(Top100Status ~ . - 1, data = test_data), s = "lambda.min", type = "response")
ridge_pred_prob <- predict(cv_ridge, newx = model.matrix(Top100Status ~ . - 1, data = test_data), s = "lambda.min", type = "response")
# Convert probabilities to class predictions based on a threshold (default is 0.5)
lasso_pred_class <- ifelse(lasso_pred_prob > 0.5, 1, 0)
ridge_pred_class <- ifelse(ridge_pred_prob > 0.5, 1, 0)
# Confusion matrix for the Lasso model
lasso_conf_matrix <- confusionMatrix(factor(lasso_pred_class), factor(test_data$Top100Status))
print("Confusion Matrix for Lasso Model:")
print(lasso_conf_matrix)
# Confusion matrix for the Ridge model
ridge_conf_matrix <- confusionMatrix(factor(ridge_pred_class), factor(test_data$Top100Status))
print("Confusion Matrix for Ridge Model:")
print(ridge_conf_matrix)
library(rpart)
# Fit decision tree model
tree_model <- rpart(Top100Status ~ ., data = train_data, method = "class")
# Predictions and evaluation
tree_predictions <- predict(tree_model, test_data, type = "class")
confusionMatrix(tree_predictions, factor(test_data$Top100Status))
library(randomForest)
# Fit random forest model
rf_model <- randomForest(Top100Status ~ ., data = train_data)
# Predictions and evaluation
rf_predictions <- predict(rf_model, test_data)
confusionMatrix(rf_predictions, factor(test_data$Top100Status))
# Ensuring that both predictions and actual values are factors with the same levels
rf_predictions_factor <- factor(rf_predictions, levels = c(0, 1))
test_data_factor <- factor(test_data$Top100Status, levels = c(0, 1))
# Now try the confusion matrix again
conf_matrix <- confusionMatrix(rf_predictions_factor, test_data_factor)
print(conf_matrix)
library(randomForest)
# Fit random forest model
rf_model <- randomForest(Top100Status ~ ., data = train_data)
# Predictions and evaluation
rf_predictions <- predict(rf_model, test_data)
confusionMatrix(rf_predictions, factor(test_data$Top100Status))
rf_predictions
confusionMatrix(rf_predictions, factor(test_data$Top100Status))
binary_predictions <- as.factor(ifelse(rf_predictions > 0.5, 1, 0))
test_data$Top100Status <- factor(test_data$Top100Status, levels = c("0", "1"))
library(caret)
conf_matrix <- confusionMatrix(binary_predictions, test_data$Top100Status)
print(conf_matrix)
library(e1071)
# Fit SVM model
svm_model <- svm(Top100Status ~ ., data = train_data, type = "C-classification", kernel = "radial")
# Predictions and evaluation
svm_predictions <- predict(svm_model, test_data)
confusionMatrix(svm_predictions, factor(test_data$Top100Status))
library(e1071)
# Fit Naive Bayes model
nb_model <- naiveBayes(Top100Status ~ ., data = train_data)
# Predictions
nb_predictions <- predict(nb_model, test_data)
# Model evaluation
nb_conf_mat <- confusionMatrix(nb_predictions, test_data$Top100Status)
print(nb_conf_mat)
library(gbm)
library(gbm)
install.packages("gbm")
library(gbm)
# Fit GBM model
gbm_model <- gbm(Top100Status ~ ., data = train_data, distribution = "bernoulli", n.trees = 100, interaction.depth = 3, shrinkage = 0.1)
# Predictions
gbm_predictions <- predict(gbm_model, test_data, n.trees = 100, type = "response")
gbm_pred_class <- ifelse(gbm_predictions > 0.5, 1, 0)
# Model evaluation
gbm_conf_mat <- confusionMatrix(factor(gbm_pred_class), factor(test_data$Top100Status))
print(gbm_conf_mat)
library(nnet)
# Fit Neural Network model
nn_model <- nnet(Top100Status ~ ., data = train_data, size = 5, linout = TRUE, decay = 5e-4, maxit = 200)
# Predictions
nn_predictions <- predict(nn_model, test_data, type = "raw")
nn_pred_class <- ifelse(nn_predictions > 0.5, 1, 0)
# Model evaluation
nn_conf_mat <- confusionMatrix(factor(nn_pred_class), factor(test_data$Top100Status))
print(nn_conf_mat)
library(nnet)
# Fit Neural Network model
nn_model <- nnet(Top100Status ~ ., data = train_data, size = 5, linout = TRUE, decay = 5e-4, maxit = 1200)
# Predictions
nn_predictions <- predict(nn_model, test_data, type = "raw")
nn_pred_class <- ifelse(nn_predictions > 0.5, 1, 0)
# Model evaluation
nn_conf_mat <- confusionMatrix(factor(nn_pred_class), factor(test_data$Top100Status))
print(nn_conf_mat)
library(nnet)
# Fit Neural Network model
nn_model <- nnet(Top100Status ~ ., data = train_data, size = 5, linout = TRUE, decay = 5e-4, maxit = 5000)
# Predictions
nn_predictions <- predict(nn_model, test_data, type = "raw")
nn_pred_class <- ifelse(nn_predictions > 0.5, 1, 0)
# Model evaluation
nn_conf_mat <- confusionMatrix(factor(nn_pred_class), factor(test_data$Top100Status))
print(nn_conf_mat)
library(nnet)
# Fit Neural Network model
nn_model <- nnet(Top100Status ~ ., data = train_data, size = 5, linout = TRUE, decay = 5e-4, maxit = 5000)
# Predictions
nn_predictions <- predict(nn_model, test_data, type = "raw")
nn_pred_class <- ifelse(nn_predictions > 0.5, 1, 0)
# Model evaluation
nn_conf_mat <- confusionMatrix(factor(nn_pred_class), factor(test_data$Top100Status))
print(nn_conf_mat)
library(nnet)
# Fit Neural Network model
nn_model <- nnet(Top100Status ~ ., data = train_data, size = 5, linout = FALSE, decay = 5e-4, maxit = 5000)
# Predictions
nn_predictions <- predict(nn_model, test_data, type = "raw")
nn_pred_class <- ifelse(nn_predictions > 0.5, 1, 0)
# Model evaluation
nn_conf_mat <- confusionMatrix(factor(nn_pred_class), factor(test_data$Top100Status))
print(nn_conf_mat)
library(nnet)
# Fit Neural Network model
nn_model <- nnet(Top100Status ~ ., data = train_data, size = 5, linout = TRUE, decay = 5e-4, maxit = 5000)
# Predictions
nn_predictions <- predict(nn_model, test_data, type = "raw")
nn_pred_class <- ifelse(nn_predictions > 0.5, 1, 0)
# Model evaluation
nn_conf_mat <- confusionMatrix(factor(nn_pred_class), factor(test_data$Top100Status))
print(nn_conf_mat)
library(nnet)
library(caret)  # Ensure caret is loaded for confusionMatrix
# Fit Neural Network model with trace set to FALSE to reduce verbosity
nn_model <- nnet(Top100Status ~ ., data = train_data, size = 5, linout = TRUE, decay = 5e-4, maxit = 5000, trace = FALSE)
# Predictions
nn_predictions <- predict(nn_model, test_data, type = "raw")
nn_pred_class <- ifelse(nn_predictions > 0.5, 1, 0)
# Model evaluation
nn_conf_mat <- confusionMatrix(factor(nn_pred_class), factor(test_data$Top100Status))
print(nn_conf_mat)
library(nnet)
library(caret)  # Ensure caret is loaded for confusionMatrix
# Fit Neural Network model with trace set to FALSE to reduce verbosity
nn_model <- nnet(Top100Status ~ ., data = train_data, size = 5, linout = TRUE, decay = 5e-4, maxit = 50000, trace = FALSE)
# Predictions
nn_predictions <- predict(nn_model, test_data, type = "raw")
nn_pred_class <- ifelse(nn_predictions > 0.5, 1, 0)
# Model evaluation
nn_conf_mat <- confusionMatrix(factor(nn_pred_class), factor(test_data$Top100Status))
print(nn_conf_mat)
library(dplyr)
library(tidyr)
library(caret)
library(corrplot)
data <- read.csv("dataset/processed_data.csv")
data <- data %>% select(WinsAboveReplacement)
colnames(data)
print(head(data$Top100Status))
data$Top100Status <- ifelse(data$Top100Status == "No", 0, 1)
library(dplyr)
library(caret)
library(corrplot)
library(e1071)
library(randomForest)
library(nnet)
library(gbm)
data <- read.csv("dataset/processed_data.csv")
data <- data %>% select(WinsAboveReplacement)
library(dplyr)
library(caret)
library(corrplot)
library(e1071)
library(randomForest)
library(nnet)
library(gbm)
data <- read.csv("dataset/processed_data.csv")
data$Top100Status <- ifelse(data$Top100Status == "No", 0, 1)
data <- data %>% select(WinsAboveReplacement, Top100Status)
colnames(data)
print(head(data$Top100Status))
data$Top100Status <- ifelse(data$Top100Status == "No", 0, 1)
print(head(data$Top100Status))
library(dplyr)
library(caret)
library(corrplot)
library(e1071)
library(randomForest)
library(nnet)
library(gbm)
data <- read.csv("dataset/processed_data.csv")
data$Top100Status <- ifelse(data$Top100Status == "No", 0, 1)
data <- data %>% select(WinsAboveReplacement, Top100Status)
colnames(data)
print(head(data$Top100Status))
data$Top100Status <- ifelse(data$Top100Status == "No", 0, 1)
print(head(data$Top100Status))
set.seed(123)
index <- createDataPartition(data$Top100Status, p = 0.8, list = FALSE)
library(dplyr)
library(caret)
library(corrplot)
library(e1071)
library(randomForest)
library(nnet)
library(gbm)
data <- read.csv("dataset/processed_data.csv")
data$Top100Status <- ifelse(data$Top100Status == "No", 0, 1)
data <- data %>% select(WinsAboveReplacement, Top100Status)
colnames(data)
set.seed(123)
index <- createDataPartition(data$Top100Status, p = 0.8, list = FALSE)
train_data <- data[index,]
test_data <- data[-index,]
# Fit logistic regression model using only WAR
logit_model <- glm(Top100Status ~ WinsAboveReplacement, data = train_data, family = binomial())
# Predictions and evaluation
predictions <- predict(logit_model, test_data, type = "response")
predicted_class <- ifelse(predictions > 0.5, 1, 0)
confusionMatrix(factor(predicted_class), factor(test_data$Top100Status))
library(glmnet)
x <- model.matrix(Top100Status ~ . - 1, data = train_data)  # -1 to exclude intercept
y <- train_data$Top100Status
lasso_model <- glmnet(x, y, family = "binomial", alpha = 1)
# Prepare matrix for glmnet
x <- model.matrix(Top100Status ~ WinsAboveReplacement - 1, data = train_data)
y <- train_data$Top100Status
# Fit Lasso and Ridge models
lasso_model <- glmnet(x, y, family = "binomial", alpha = 1)
# Fit decision tree model
tree_model <- rpart(Top100Status ~ WinsAboveReplacement, data = train_data, method = "class")
# Predictions and evaluation
tree_predictions <- predict(tree_model, test_data, type = "class")
confusionMatrix(tree_predictions, factor(test_data$Top100Status))
# Fit random forest model
rf_model <- randomForest(Top100Status ~ WinsAboveReplacement, data = train_data)
# Predictions and evaluation
rf_predictions <- predict(rf_model, test_data)
confusionMatrix(as.factor(rf_predictions > 0.5), factor(test_data$Top100Status))
# Fit random forest model
rf_model <- randomForest(Top100Status ~ WinsAboveReplacement, data = train_data)
# Predictions and evaluation
rf_predictions <- predict(rf_model, test_data)
rf_predictions <- predict(rf_model, test_data)
binary_predictions <- as.factor(ifelse(rf_predictions > 0.5, 1, 0))
# Ensure both actual and predicted factors have the same levels
binary_predictions <- factor(binary_predictions, levels = c(0, 1))
test_data$Top100Status <- factor(test_data$Top100Status, levels = c(0, 1))
# Confusion matrix
conf_matrix <- confusionMatrix(binary_predictions, test_data$Top100Status)
print(conf_matrix)
# Fit SVM model
svm_model <- svm(Top100Status ~ WinsAboveReplacement, data = train_data, type = "C-classification", kernel = "radial")
# Predictions and evaluation
svm_predictions <- predict(svm_model, test_data)
confusionMatrix(svm_predictions, factor(test_data$Top100Status))
# Fit Naive Bayes model
nb_model <- naiveBayes(Top100Status ~ WinsAboveReplacement, data = train_data)
# Predictions
nb_predictions <- predict(nb_model, test_data)
# Model evaluation
confusionMatrix(nb_predictions, factor(test_data$Top100Status))
# Fit GBM model
gbm_model <- gbm(Top100Status ~ WinsAboveReplacement, data = train_data, distribution = "bernoulli", n.trees = 100, interaction.depth = 3, shrinkage = 0.1)
# Predictions
gbm_predictions <- predict(gbm_model, test_data, n.trees = 100, type = "response")
gbm_pred_class <- ifelse(gbm_predictions > 0.5, 1, 0)
# Model evaluation
confusionMatrix(factor(gbm_pred_class), factor(test_data$Top100Status))
# Fit Neural Network model
nn_model <- nnet(Top100Status ~ WinsAboveReplacement, data = train_data, size = 5, linout = TRUE, decay = 5e-4,
library(nnet)
library(caret)  # Ensure caret is loaded for confusionMatrix
# Fit Neural Network model with trace set to FALSE to reduce verbosity
nn_model <- nnet(Top100Status ~ WinsAboveReplacement, data = train_data, size = 5, linout = TRUE, decay = 5e-4, maxit = 5000, trace = FALSE)
# Predictions: Convert raw outputs to probability using the logistic function
nn_predictions <- predict(nn_model, test_data, type = "raw")
nn_pred_prob <- 1 / (1 + exp(-nn_predictions))  # Logistic transformation to probabilities
nn_pred_class <- ifelse(nn_pred_prob > 0.5, 1, 0)  # Convert probabilities to binary class
# Ensure both predicted and actual classes are factors with the same levels
nn_pred_class <- factor(nn_pred_class, levels = c(0, 1))
test_data$Top100Status <- factor(test_data$Top100Status, levels = c(0, 1))
# Model evaluation using confusion matrix
nn_conf_mat <- confusionMatrix(nn_pred_class, test_data$Top100Status)
print(nn_conf_mat)
library(nnet)
library(caret)  # Ensure caret is loaded for confusionMatrix
# Fit Neural Network model with trace set to FALSE to reduce verbosity
nn_model <- nnet(Top100Status ~ WinsAboveReplacement, data = train_data, size = 5, linout = TRUE, decay = 5e-4, maxit = 5000, trace = FALSE)
# Predictions: Convert raw outputs to probability using the logistic function
nn_predictions <- predict(nn_model, test_data, type = "raw")
nn_pred_prob <- 1 / (1 + exp(-nn_predictions))  # Logistic transformation to probabilities
nn_pred_class <- ifelse(nn_pred_prob > 0.5, 1, 0)  # Convert probabilities to binary class
# Ensure both predicted and actual classes are factors with the same levels
nn_pred_class <- factor(nn_pred_class, levels = c(0, 1))
test_data$Top100Status <- factor(test_data$Top100Status, levels = c(0, 1))
# Model evaluation using confusion matrix
nn_conf_mat <- confusionMatrix(nn_pred_class, test_data$Top100Status)
print(nn_conf_mat)
