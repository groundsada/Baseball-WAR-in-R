---
title: 'R Notebook'
output: html_notebook
---

# Introduction

This notebook is designed to scrape and process player ratings data from ESPN for Major League Baseball (MLB) players. The data is collected yearly, cleaned, and saved for further analysis.

## Setup Libraries

We begin by loading the necessary R package for web scraping.


```{r}
library(rvest)
```

# Load Web Page Function

This function is designed to handle the connection to the ESPN website and retrieve the page content for a given year and page number. The function will retry the connection in case of an error.

```{r}
load_page <- function(year, onPageOne) {
  
  base <- 'https://www.espn.com/mlb/playerratings/_/year/'
  url <- if (onPageOne) paste(base, year, sep = '') else paste(base, year, '/page/2', sep = '')
  
  connected <- FALSE
  page <- NULL
  
  while(!connected) {
    result <- tryCatch({
      con <- url(url, 'rb')
      page <- read_html(con)
      close(con)
      connected <- TRUE
    }, error = function(e) {
      cat('\n', year, onPageOne, '\n\n')
    })
  }
  return(page)
}

```

## Extract Table from Page

This function extracts the third table from the loaded web page, which contains the player ratings we are interested in.

```{r}

get_table_from_page <- function(page) {
  
  tables <- page %>%
    html_nodes('table') %>%
    html_table()
  
  table <- tables[[3]]
  return(table)
  
}

```

## Clean the Table

Once the table is extracted, this function cleans the data by removing unnecessary rows and columns, and setting appropriate column names.


```{r}

clean_table <- function(table) {
  
  df <- unserialize(serialize(table, NULL))
  df <- df[-c(1, 2, 3), ]
  df <- df[, 1:4]
  names(df) <- c('Rank', 'Player', 'Team', 'Position')
  return(df)
  
}

```

## Load, Extract, and Clean Table

This function integrates the previous functions to load a page, extract the table, and clean it for a given year and page indicator (first page or second page).

```{r}

load_page_and_clean_table <- function(year, onPageOne) {
  
  page <- load_page(year, onPageOne)
  table <- get_table_from_page(page)
  table <- clean_table(table)
  return(table)
  
}

```

# Get Data for Each Year

For each year, this function combines data from two pages into a single dataframe.

```{r}

get_dataframe_for_year <- function(year) {
  
  df_1 <- load_page_and_clean_table(year, TRUE)
  df_2 <- load_page_and_clean_table(year, FALSE)
  combined_df <- rbind(df_1, df_2)
  return(combined_df)
  
}

```

# Save Data to CSV

This function saves the cleaned and combined dataframe to a CSV file, organizing files by year within a dedicated directory.


```{r}
save_dataframe_to_csv <- function(df, year) {
  
  file_name = paste('top_100_each_year/top_players_', year, '.csv', sep = '')
  write.csv(df, file = file_name, row.names = FALSE)
  
}
```

# Main Execution Block

This block calculates the range of years to process, retrieves data for each year, and saves it as CSV files.


```{r}

last_year <- as.numeric(format(Sys.Date(), '%Y')) - 1
num_years <- last_year - 2008 + 1
years <- seq(last_year, by = -1, length.out = num_years)

for (year in years) {
  df <- get_dataframe_for_year(year)
  save_dataframe_to_csv(df, year)
}

```



