---
title: "R Notebook"
output: html_notebook
---


# Clean up


```{r}
library(dplyr)
library(tidyr)
library(caret)
library(corrplot)

# Load your data
data <- read.csv("dataset/master_rank.csv")
```

```{r}
print(length(colnames(data)))
print(nrow(data))
```

```{r}
# Step 1: Data Cleaning
# Handling missing values
data <- data %>%
  mutate(across(where(is.numeric), ~ifelse(is.na(.), mean(., na.rm = TRUE), .))) %>%
  mutate(across(where(is.character), ~ifelse(is.na(.), "Unknown", .)))
```



```{r}
print(length(colnames(data)))
print(nrow(data))
total_NAs <- sum(is.na(data))
print(paste("Total NA values in the dataset:", total_NAs))
```


```{r}
numeric_columns <- sapply(data, is.numeric)
data[numeric_columns] <- scale(data[numeric_columns])
```


```{r}
colnames(data)
```


```{r}
# Step 4: Checking for high correlations
cor_data <- cor(data[, sapply(data, is.numeric)], use = "complete.obs")
high_cor_pairs <- which(cor_data > 0.86 & upper.tri(cor_data), arr.ind = TRUE)

# Create a table of highly correlated pairs
if (length(high_cor_pairs) > 0) {
  high_cor_data <- data.frame(
    Feature1 = names(data)[high_cor_pairs[, 1]],
    Feature2 = names(data)[high_cor_pairs[, 2]],
    Correlation = cor_data[high_cor_pairs]
  )
  print("Highly correlated pairs (above 0.86):")
  print(high_cor_data)
} else {
  print("No highly correlated pairs found.")
}
```


```{r}
# Function to drop columns
drop_columns <- function(data, columns_to_drop) {
  data[, !names(data) %in% columns_to_drop]
}

columns_to_drop <- c("Age.y", "Rk", "Pos", "G.x", "PA", "AB", "X2B.x", "RBI", "SB", "CS", "SLG", "source.x", "source.y", "IBB", "OPS", "BA", "OBP")

# Drop the specified columns from the dataset
data <- drop_columns(data, columns_to_drop)


```


```{r}
# Rename the columns using the `names()` function
names(data) <- c(
  "PlayerName", "Team", "Year", "Age", "RunsScored", "Hits", "Triples", "HomeRuns",
  "BaseOnBalls", "Strikeouts", "AdjustedOPS", "TotalBases", "GroundedIntoDoublePlays",
  "HitByPitch", "SacrificeHits", "SacrificeFlies", "Country", "BattingHand", "ThrowingHand",
  "Height", "Weight", "DateOfBirth", "YearsPlayed", "GamesYear", "GamesStarted",
  "BattingStats", "DefenseStats", "Pitching", "Catching", "FirstBase", "SecondBase",
  "ThirdBase", "ShortStop", "LeftField", "CenterField", "RightField", "Outfield", "DesignatedHitter",
  "PinchHitter", "PinchRunner", "WinsAboveReplacement", "Salary", "UnknownX1", "Top100Status"
)

# Clarify or investigate what 'UnknownX1' represents
# If 'UnknownX1' is still unidentified or not useful, consider dropping it as well

columns_to_drop <- c("SacrificeHits", "SacrificeFlies", "GroundedIntoDoublePlays", "UnknownX1")  # Update based on new info

# Drop the specified columns from the dataset using previously defined function
data <- drop_columns(data, columns_to_drop)


print(length(colnames(data)))
colnames(data)
```


```{r}
cor_data <- cor(data[, sapply(data, is.numeric)], use = "complete.obs")
high_cor_pairs <- which(cor_data > 0.92 & upper.tri(cor_data), arr.ind = TRUE)

# Create a table of highly correlated pairs
if (length(high_cor_pairs) > 0) {
  high_cor_data <- data.frame(
    Feature1 = names(data)[high_cor_pairs[, 1]],
    Feature2 = names(data)[high_cor_pairs[, 2]],
    Correlation = cor_data[high_cor_pairs]
  )
  print("Highly correlated pairs (above 0.92):")
  print(high_cor_data)
} else {
  print("No highly correlated pairs found.")
}
```


```{r}
columns_to_drop <- c("HomeRuns", "Triples", "Strikeouts", "HitByPitch", "Country", "BattingHand", "ThrowingHand", "Age", "Height", "BaseOnBalls")
data <- drop_columns(data, columns_to_drop)
```


```{r}
colnames(data)
```
# Heatmap

```{r}
corrplot(cor_data, method = "color", order = "hclust", tl.cex = 0.6,
         title = "Heatmap of Correlation Matrix", 
         tl.col = "black", tl.srt = 90)

```
As we can see, WAR isn't highly correlated to one feature.

# PCA

```{r}
pca_model <- prcomp(data[, sapply(data, is.numeric)], center = TRUE, scale. = TRUE)
summary(pca_model)
```

 - The first principal component captures 35.92% of the variance within the dataset, highlighting its significant role in encompassing the key features and variations of the data.
 - By retaining the first 10 principal components, which cumulatively account for over 81% of the dataset's variance, we can effectively reduce dimensionality while preserving the majority of the information.
 - The rapid decline in the proportion of variance explained by subsequent components beyond the 15th (reaching nearly 97.23% cumulative variance), suggests that further components contribute minimally to the data's overall structure.
 - These results support using the top 10 to 15 components for further data analysis, simplifying the computational demands and potentially enhancing the clarity of patterns and trends in the data.
 

 
```{r}
plot(pca_model, type = "l")
```

# Step 2: Exploratory Data Analysis (EDA)

## Descriptive Statistics:


```{r}
library(ggplot2)

# Boxplot for Wins Above Replacement (WAR)
ggplot(data, aes(y = WinsAboveReplacement)) + 
  geom_boxplot(fill = "blue", alpha = 0.5) +
  theme_minimal() +
  labs(title = "Boxplot of Wins Above Replacement (WAR)", y = "WAR")
```




```{r}
# Histogram for Wins Above Replacement (WAR)
ggplot(data, aes(x = WinsAboveReplacement)) + 
  geom_histogram(bins = 30, fill = "red", color = "black") +
  theme_minimal() +
  labs(title = "Histogram of Wins Above Replacement (WAR)", x = "WAR")

```


### For other continuous variables (example: TotalBases)

```{r}
ggplot(data, aes(x = TotalBases)) + 
  geom_histogram(bins = 30, fill = "green", color = "black") +
  theme_minimal() +
  labs(title = "Histogram of Total Bases", x = "Total Bases")
```


### Compute 5-Number Summaries

```{r}
# Selecting only continuous variables for summary
continuous_vars <- data[, sapply(data, is.numeric)]
summary(continuous_vars)

```

### Findings:
- **Performance Variability**: There is considerable variability in player performance across different metrics, with a few outliers significantly outperforming others.
- **Skewness in Distributions**: Many of the metrics show right-skewed distributions, where the majority of players are below the average, pulled up by high-performing outliers.
- **Physical and Role Diversity**: The wide range in physical stats (like Weight) and role-specific stats (like Games Started or Pitching) reflects the diversity in player roles and physical builds, emphasizing the varied nature of professional baseball.
- **Impact Players**: The range in Wins Above Replacement highlights the presence of both underperformers and impact players within the league, showcasing the potential for significant individual contributions to team success.

# Step 3: Answering Specific Questions

## Correlation with Team Success


```{r}
# Assuming 'team_wins', 'playoff_appearances', and 'championships' are in your dataset
# Calculate Spearman's correlation
correlations <- cor(data[c("WinsAboveReplacement", "team_wins", "playoff_appearances", "championships")], 
                    method = "spearman", use = "complete.obs")
print(correlations)

# Plot WAR vs team wins as an example
ggplot(data, aes(x = WinsAboveReplacement, y = team_wins)) +
  geom_point() +
  geom_smooth(method = "lm", col = "blue") +
  labs(title = "Scatter Plot of WAR vs Team Wins", x = "Wins Above Replacement", y = "Team Wins")

```




```{r}

```




```{r}

```




```{r}

```




```{r}

```




```{r}

```




```{r}

```




```{r}

```




```{r}

```




```{r}

```




```{r}

```




```{r}

```




```{r}

```




